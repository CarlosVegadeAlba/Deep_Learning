# 1. Introduction

* Supervised learning
* Unsupervised learning
* Reinforcement learning
* Fairness
* Explainability

# 2. Supervised learning

* Classification
* Regression
* Logistic regression
* Performance measure
* Model evaluation
* Bias-variance tradeoff
* Training set
* Validation set
* Test set

# 3. Shallow neural networks

* Neural network
* Forward-propagation
* Back-propagation
* Gradient
* Parameter
* Hyperparameter
* Model selection
* Universal approximation theorem
* Vectorization
* Activation function (relu, sigmoid, tanh)
* Bias
* Weight

# 4. Deep neural networks

* Deep neural networks
* Layer

# 5. Loss functions

* Softmax
* Cross-entropy loss

# 6. Fitting models

* Gradient descent
* Stochastic gradient descent
* Mini-batch
* Learning rate decay
* Momentum
* RMSprop
* Adam

# 7. Gradients and initialization

* Initialization

# 8. Measuring performance

* Regularization
* Dropout
* Early stopping

# 9. Convolutional networks

* Convolutional neural network
* Padding
* Stride
* Pooling layer
* 1x1 convolutions
* Inception blocks
* Residual blocks
* Dense blocks

# 10. Residual networks

* Skip connection
* Residual blocks
* Exploding gradient
* Vanishing gradient
* Batch normalization

# 11. Transformers

* Language model
* Attention
* Self-supervised learning
* Transformers
* Encoder-decoder architecture

# Additional Terms:

* Bias in word embeddings
* Anchor boxes
* Beam search
* Bidirectional RNN
* CBOW
* Cosine similarity
* Exploding gradient
* GloVe
* Hierarchical softmax
* Intersection over union (IoU)
* Leaky average
* Negative sampling
* Neural language model
* Nonmax suppression
* Object localization
* Object detection
* Sentiment classification
* Sequence model
* Skipgram
* Word2vec
* Word embedding
